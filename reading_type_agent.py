import os
import json
import csv
import datetime
import xml.etree.ElementTree as ET
from difflib import SequenceMatcher
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®DeepSeek APIå¯†é’¥
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

class ReadingTypeAgent:
    def __init__(self):
        self.conversation_history = []
        # ä½¿ç”¨OpenAIå®¢æˆ·ç«¯ï¼Œé…ç½®DeepSeekåŸºç¡€URL
        self.client = OpenAI(
            api_key=DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com"
        )
        
        # æ•°æ®æ–‡ä»¶è·¯å¾„
        self.codes_file = "reading_type_codes.csv"
        self.dictionaries_file = "field_dictionaries.csv"
        self.history_file = "operation_history.csv"
        
        # åŠ è½½æ•°æ®
        self.reading_type_codes = self.load_reading_type_codes()
        self.field_dictionaries = self.load_field_dictionaries()
        
        # ReadingTypeå­—æ®µå®šä¹‰
        self.field_names = [
            "macroPeriod", "aggregate", "measurePeriod", "accumulationBehaviour",
            "flowDirection", "commodity", "measurementKind", "harmonic",
            "argumentNumerator", "TOU", "cpp", "tier", "phase", "multiplier", "uom", "currency"
        ]
        
        # è®¾ç½®å¯ç”¨å·¥å…·
        self.available_tools = {
            "search_reading_type": self.search_reading_type,
            "generate_reading_type": self.generate_reading_type,
            "query_dictionary": self.query_dictionary,
            "export_data": self.export_data,
            "view_codes_library": self.view_codes_library,
            "filter_codes": self.filter_codes,
            "add_to_library": self.add_to_library
        }
    
    def load_reading_type_codes(self):
        """åŠ è½½ReadingTypeç¼–ç åº“"""
        try:
            df = pd.read_csv(self.codes_file)
            return df.to_dict('records')
        except FileNotFoundError:
            print(f"è­¦å‘Š: ç¼–ç åº“æ–‡ä»¶ {self.codes_file} æœªæ‰¾åˆ°")
            return []
    
    def load_field_dictionaries(self):
        """åŠ è½½å­—æ®µå­—å…¸"""
        try:
            df = pd.read_csv(self.dictionaries_file)
            # æŒ‰å­—æ®µååˆ†ç»„
            dictionaries = {}
            for _, row in df.iterrows():
                field_name = row['field_name'].strip()
                if field_name not in dictionaries:
                    dictionaries[field_name] = []
                dictionaries[field_name].append({
                    'value': row['field_value'],
                    'display_name': row['display_name'],
                    'description': row['description'],
                    'is_custom': row.get('is_custom', False)
                })
            return dictionaries
        except FileNotFoundError:
            print(f"è­¦å‘Š: å­—å…¸æ–‡ä»¶ {self.dictionaries_file} æœªæ‰¾åˆ°")
            return {}
    
    def add_message(self, role, content):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.conversation_history.append({"role": role, "content": content})
    
    def search_reading_type(self, args):
        """åœ¨ç¼–ç åº“ä¸­æœç´¢ReadingTypeID"""
        search_term = args.get("name", "").strip()
        
        if not search_term:
            return "âŒ è¯·æä¾›è¦æœç´¢çš„é‡æµ‹åç§°"
        
        # ç²¾ç¡®åŒ¹é…
        exact_matches = []
        fuzzy_matches = []
        
        for code in self.reading_type_codes:
            name = code.get('name', '')
            description = code.get('description', '')
            
            # ç²¾ç¡®åŒ¹é…
            if search_term.lower() == name.lower():
                exact_matches.append(code)
            # æ¨¡ç³ŠåŒ¹é…
            elif (search_term.lower() in name.lower() or 
                  search_term.lower() in description.lower() or
                  self.similarity(search_term, name) > 0.6):
                fuzzy_matches.append((code, self.similarity(search_term, name)))
        
        # æ„å»ºè¿”å›ç»“æœ
        result = []
        
        if exact_matches:
            result.append("âœ… æ‰¾åˆ°ç²¾ç¡®åŒ¹é…:")
            for match in exact_matches:
                result.append(f"ğŸ“Š åç§°: {match.get('name', 'N/A')}")
                result.append(f"ğŸ”¢ ReadingTypeID: {match.get('reading_type_id', 'N/A')}")
                result.append(f"ğŸ“ è¯´æ˜: {match.get('description', 'N/A')}")
                result.append(f"ğŸ·ï¸ ç±»åˆ«: {match.get('category', 'N/A')}")
                result.append(f"â° åˆ›å»ºæ—¶é—´: {match.get('created_at', 'N/A')}")
                result.append("---")
        
        if fuzzy_matches and not exact_matches:
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            fuzzy_matches.sort(key=lambda x: x[1], reverse=True)
            result.append("ğŸ” æ‰¾åˆ°ç›¸ä¼¼çš„ç¼–ç :")
            for i, (match, similarity) in enumerate(fuzzy_matches[:5], 1):
                result.append(f"{i}. {match.get('name', 'N/A')} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                result.append(f"   ReadingTypeID: {match.get('reading_type_id', 'N/A')}")
                result.append(f"   è¯´æ˜: {match.get('description', 'N/A')}")
            result.append("\nâ“ ä»¥ä¸Šæ˜¯å¦æœ‰æ‚¨éœ€è¦çš„ç¼–ç ï¼Ÿå¦‚æœæ²¡æœ‰ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨ç”Ÿæˆæ–°çš„ç¼–ç ã€‚")
        
        if not exact_matches and not fuzzy_matches:
            result.append(f"âŒ æœªæ‰¾åˆ°ä¸'{search_term}'ç›¸å…³çš„ç¼–ç ")
            result.append("ğŸ’¡ æˆ‘å¯ä»¥ä¸ºæ‚¨ç”Ÿæˆæ–°çš„ReadingTypeIDï¼Œè¯·å‘Šè¯‰æˆ‘æ›´å¤šè¯¦ç»†ä¿¡æ¯:")
            result.append("- è®¾å¤‡ç±»å‹ (å¦‚: ç”µè¡¨ã€å‚¨èƒ½ã€æ°”è±¡)")
            result.append("- æµ‹é‡å†…å®¹ (å¦‚: ç”µå‹ã€ç”µæµã€åŠŸç‡ã€èƒ½é‡)")
            result.append("- ç‰¹æ®Šè¦æ±‚ (å¦‚: ç›¸ä½ã€æ—¶é—´å‘¨æœŸ)")
        
        # è®°å½•æ“ä½œå†å²
        self.log_operation(search_term, "search", "\n".join(result))
        
        return "\n".join(result)
    
    def generate_reading_type(self, args):
        """æ ¹æ®è§£æçš„å­—æ®µç”ŸæˆReadingTypeID"""
        # è·å–ç”¨æˆ·æè¿°
        description = args.get("description", "")
        field_values = args.get("field_values", {})
        
        if not description and not field_values:
            return "âŒ è¯·æä¾›é‡æµ‹æè¿°æˆ–å­—æ®µå€¼"
        
        try:
            # å¦‚æœæœ‰å­—æ®µå€¼ï¼Œç›´æ¥ç”Ÿæˆ
            if field_values:
                reading_type_id = self.build_reading_type_id(field_values)
                result = []
                result.append("ğŸ¤– AIç”Ÿæˆç»“æœ:")
                result.append(f"ğŸ”¢ ReadingTypeID: {reading_type_id}")
                result.append("\nğŸ“‹ å­—æ®µè¯¦æƒ…:")
                
                for i, field_name in enumerate(self.field_names):
                    value = field_values.get(f"field_{i+1}", 0)
                    field_info = self.get_field_description(field_name, value)
                    result.append(f"  {field_name}: {value} ({field_info})")
                
                result.append("\nâœ… æ˜¯å¦é‡‡çº³æ­¤ç¼–ç ï¼Ÿè¾“å…¥'æ˜¯'ç¡®è®¤ï¼Œ'å¦'å–æ¶ˆï¼Œæˆ–æå‡ºä¿®æ”¹å»ºè®®ã€‚")
                return "\n".join(result)
            
            # åŸºäºæè¿°è¿›è¡ŒAIåˆ†æç”Ÿæˆ
            analysis = self.analyze_measurement_description(description)
            if analysis:
                reading_type_id = self.build_reading_type_id(analysis)
                
                result = []
                result.append("ğŸ¤– AIåˆ†æç»“æœ:")
                result.append(f"ğŸ“ è¾“å…¥æè¿°: {description}")
                result.append("\nğŸ“‹ è¯†åˆ«è¦ç´ :")
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                for field_name, value in analysis.items():
                    if value != 0:  # åªæ˜¾ç¤ºéé›¶å­—æ®µ
                        field_info = self.get_field_description(field_name.replace('field_', ''), value)
                        result.append(f"  - {field_name}: {value} ({field_info})")
                
                result.append(f"\nğŸ’¡ å»ºè®®ç¼–ç : {reading_type_id}")
                result.append("\nâœ… æ˜¯å¦é‡‡çº³æ­¤ç¼–ç ï¼Ÿè¾“å…¥'æ˜¯'ç¡®è®¤ï¼Œ'å¦'å–æ¶ˆï¼Œæˆ–æå‡ºä¿®æ”¹å»ºè®®ã€‚")
                
                # è®°å½•æ“ä½œå†å²
                self.log_operation(description, "generate", "\n".join(result))
                
                return "\n".join(result)
            else:
                return "âŒ æ— æ³•è§£ææè¿°ï¼Œè¯·æä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯æˆ–ä½¿ç”¨æ ‡å‡†æœ¯è¯­"
                
        except Exception as e:
            return f"âŒ ç”Ÿæˆç¼–ç æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
    
    def analyze_measurement_description(self, description):
        """åˆ†æé‡æµ‹æè¿°å¹¶æ¨æ–­å­—æ®µå€¼"""
        # è¿™é‡Œå®ç°åŸºäºå…³é”®è¯çš„ç®€å•æ˜ å°„
        analysis = {f"field_{i+1}": 0 for i in range(16)}
        
        desc_lower = description.lower()
        
        # commodity (å•†å“ç±»å‹) - field_6
        if any(word in desc_lower for word in ['ç”µ', 'ç”µåŠ›', 'ç”µèƒ½', 'ç”µå‹', 'ç”µæµ', 'åŠŸç‡']):
            analysis['field_6'] = 1  # ç”µåŠ›
        elif any(word in desc_lower for word in ['æ°”', 'å¤©ç„¶æ°”', 'ç‡ƒæ°”']):
            analysis['field_6'] = 7  # å¤©ç„¶æ°”
        elif any(word in desc_lower for word in ['æ°´']):
            analysis['field_6'] = 4  # æ°´
        elif any(word in desc_lower for word in ['çƒ­', 'è’¸æ±½']):
            analysis['field_6'] = 6  # çƒ­èƒ½
        
        # measurementKind (æµ‹é‡ç±»å‹) - field_7
        if any(word in desc_lower for word in ['ç”µå‹', 'ç”µä½']):
            analysis['field_7'] = 54  # ç”µå‹
        elif any(word in desc_lower for word in ['ç”µæµ']):
            analysis['field_7'] = 4   # ç”µæµ
        elif any(word in desc_lower for word in ['åŠŸç‡']):
            if 'æœ‰åŠŸ' in desc_lower:
                analysis['field_7'] = 37  # æœ‰åŠŸåŠŸç‡
            elif 'æ— åŠŸ' in desc_lower:
                analysis['field_7'] = 53  # æ— åŠŸåŠŸç‡
            elif 'è§†åœ¨' in desc_lower:
                analysis['field_7'] = 15  # è§†åœ¨åŠŸç‡
            else:
                analysis['field_7'] = 37  # é»˜è®¤æœ‰åŠŸåŠŸç‡
        elif any(word in desc_lower for word in ['èƒ½é‡', 'ç”µèƒ½']):
            analysis['field_7'] = 12  # èƒ½é‡
        elif any(word in desc_lower for word in ['é¢‘ç‡']):
            analysis['field_7'] = 46  # é¢‘ç‡
        elif any(word in desc_lower for word in ['æ¸©åº¦']):
            analysis['field_7'] = 139 # æ¸©åº¦
        elif any(word in desc_lower for word in ['çŠ¶æ€', 'å‘Šè­¦', 'æŠ¥è­¦']):
            analysis['field_7'] = 118 # çŠ¶æ€
        
        # flowDirection (æµå‘) - field_5
        if any(word in desc_lower for word in ['æ­£å‘', 'å……ç”µ', 'è¿›']):
            analysis['field_5'] = 1   # æ­£å‘
        elif any(word in desc_lower for word in ['åå‘', 'æ”¾ç”µ', 'å‡º']):
            analysis['field_5'] = 19  # åå‘
        elif any(word in desc_lower for word in ['å‡€', 'åŒå‘']):
            analysis['field_5'] = 4   # å‡€å€¼
        
        # accumulationBehaviour (ç´¯ç§¯è¡Œä¸º) - field_4
        if any(word in desc_lower for word in ['ç´¯ç§¯', 'ç´¯è®¡', 'æ€»']):
            analysis['field_4'] = 3   # ç´¯ç§¯
        elif any(word in desc_lower for word in ['ç¬æ—¶', 'å½“å‰', 'å®æ—¶']):
            analysis['field_4'] = 6   # ç¬æ—¶
        elif any(word in desc_lower for word in ['é—´éš”', 'åŒºé—´']):
            analysis['field_4'] = 4   # é—´éš”
        elif any(word in desc_lower for word in ['æœ€å¤§', 'å³°å€¼']):
            analysis['field_4'] = 6   # ç¬æ—¶ (ç”¨äºéœ€é‡ç­‰)
        
        # measurePeriod (æµ‹é‡å‘¨æœŸ) - field_3
        if any(word in desc_lower for word in ['15åˆ†é’Ÿ', '15min']):
            analysis['field_3'] = 2   # 15åˆ†é’Ÿ
        elif any(word in desc_lower for word in ['5åˆ†é’Ÿ', '5min']):
            analysis['field_3'] = 6   # 5åˆ†é’Ÿ
        elif any(word in desc_lower for word in ['1å°æ—¶', 'å°æ—¶']):
            analysis['field_3'] = 15  # 1å°æ—¶
        elif any(word in desc_lower for word in ['æ—¥', 'å¤©']):
            analysis['field_3'] = 11  # æ—¥
        elif any(word in desc_lower for word in ['æœˆ']):
            analysis['field_3'] = 13  # æœˆ
        
        # phase (ç›¸ä½) - field_13
        if 'aç›¸' in desc_lower or 'ç”²ç›¸' in desc_lower:
            analysis['field_13'] = 128  # Aç›¸
        elif 'bç›¸' in desc_lower or 'ä¹™ç›¸' in desc_lower:
            analysis['field_13'] = 64   # Bç›¸
        elif 'cç›¸' in desc_lower or 'ä¸™ç›¸' in desc_lower:
            analysis['field_13'] = 32   # Cç›¸
        elif 'ä¸‰ç›¸' in desc_lower:
            analysis['field_13'] = 224  # ä¸‰ç›¸åˆè®¡
        
        # multiplier (ä¹˜æ•°) - field_14
        if any(word in desc_lower for word in ['k', 'kw', 'kwh', 'åƒ']):
            analysis['field_14'] = 3    # kilo (Ã—10Â³)
        elif any(word in desc_lower for word in ['m', 'mw', 'mwh', 'å…†']):
            analysis['field_14'] = 6    # mega (Ã—10â¶)
        
        # uom (å•ä½) - field_15
        if any(word in desc_lower for word in ['wh', 'ç“¦æ—¶', 'ç”µèƒ½']):
            analysis['field_15'] = 72   # Wh
        elif any(word in desc_lower for word in ['w', 'ç“¦', 'åŠŸç‡']):
            analysis['field_15'] = 38   # W
        elif any(word in desc_lower for word in ['v', 'ä¼', 'ç”µå‹']):
            analysis['field_15'] = 29   # V
        elif any(word in desc_lower for word in ['a', 'å®‰', 'ç”µæµ']):
            analysis['field_15'] = 5    # A
        elif any(word in desc_lower for word in ['hz', 'èµ«å…¹', 'é¢‘ç‡']):
            analysis['field_15'] = 23   # Hz
        elif any(word in desc_lower for word in ['Â°c', 'æ‘„æ°åº¦', 'æ¸©åº¦']):
            analysis['field_15'] = 109  # æ‘„æ°åº¦
        
        return analysis
    
    def get_field_description(self, field_name, value):
        """è·å–å­—æ®µå€¼çš„æè¿°"""
        if field_name in self.field_dictionaries:
            for item in self.field_dictionaries[field_name]:
                if str(item['value']) == str(value):
                    return item['display_name']
        return f"å€¼: {value}"
    
    def build_reading_type_id(self, field_values):
        """æ„å»ºReadingTypeIDå­—ç¬¦ä¸²"""
        values = []
        for i in range(16):
            field_key = f"field_{i+1}"
            values.append(str(field_values.get(field_key, 0)))
        return "-".join(values)
    
    def query_dictionary(self, args):
        """æŸ¥è¯¢å­—å…¸ä¿¡æ¯"""
        field_name = args.get("field_name", "").strip()
        
        if not field_name:
            # æ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
            result = ["ğŸ“š ReadingTypeå­—æ®µå­—å…¸:"]
            for i, name in enumerate(self.field_names, 1):
                chinese_name = self.get_chinese_field_name(name)
                result.append(f"{i:2d}. {name} ({chinese_name})")
            result.append("\nğŸ’¡ ä½¿ç”¨ 'æŸ¥è¯¢å­—å…¸ [å­—æ®µå]' æŸ¥çœ‹å…·ä½“å­—æ®µçš„å¯é€‰å€¼")
            return "\n".join(result)
        
        # æŸ¥è¯¢å…·ä½“å­—æ®µ
        if field_name in self.field_dictionaries:
            result = [f"ğŸ“– å­—æ®µ '{field_name}' çš„å¯é€‰å€¼:"]
            items = self.field_dictionaries[field_name]
            
            # æŒ‰å€¼æ’åº
            sorted_items = sorted(items, key=lambda x: float(str(x['value']).replace('â€“', '-')))
            
            for item in sorted_items[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                result.append(f"  {item['value']}: {item['display_name']}")
                if item.get('description'):
                    result.append(f"    {item['description']}")
            
            if len(items) > 20:
                result.append(f"\n... è¿˜æœ‰ {len(items) - 20} ä¸ªå€¼ï¼Œä½¿ç”¨å…·ä½“æ•°å€¼æŸ¥è¯¢è¯¦æƒ…")
            
            return "\n".join(result)
        else:
            return f"âŒ æœªæ‰¾åˆ°å­—æ®µ '{field_name}'"
    
    def get_chinese_field_name(self, field_name):
        """è·å–å­—æ®µçš„ä¸­æ–‡åç§°"""
        chinese_names = {
            "macroPeriod": "å®å‘¨æœŸ",
            "aggregate": "èšåˆç±»å‹", 
            "measurePeriod": "æµ‹é‡å‘¨æœŸ",
            "accumulationBehaviour": "ç´¯ç§¯è¡Œä¸º",
            "flowDirection": "æµå‘",
            "commodity": "å•†å“ç±»å‹",
            "measurementKind": "æµ‹é‡ç±»å‹",
            "harmonic": "è°æ³¢",
            "argumentNumerator": "å‚æ•°åˆ†å­",
            "TOU": "æ—¶æ®µ",
            "cpp": "å…³é”®å³°å€¼æœŸ",
            "tier": "é˜¶æ¢¯",
            "phase": "ç›¸ä½",
            "multiplier": "ä¹˜æ•°",
            "uom": "å•ä½",
            "currency": "è´§å¸"
        }
        return chinese_names.get(field_name, field_name)
    
    def view_codes_library(self, args):
        """æŸ¥çœ‹ç¼–ç åº“"""
        page = int(args.get("page", 1))
        per_page = int(args.get("per_page", 20))
        category = args.get("category", "")
        
        # ç­›é€‰æ•°æ®
        filtered_codes = self.reading_type_codes
        if category:
            filtered_codes = [code for code in filtered_codes if code.get('category', '').lower() == category.lower()]
        
        total = len(filtered_codes)
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        page_codes = filtered_codes[start_idx:end_idx]
        
        result = [f"ğŸ“š ç¼–ç åº“ (ç¬¬{page}é¡µ, å…±{total}æ¡è®°å½•)"]
        if category:
            result[0] += f" - ç±»åˆ«: {category}"
        
        result.append("=" * 50)
        
        for i, code in enumerate(page_codes, start_idx + 1):
            result.append(f"{i:3d}. {code.get('name', 'N/A')}")
            result.append(f"     ID: {code.get('reading_type_id', 'N/A')}")
            result.append(f"     ç±»åˆ«: {code.get('category', 'N/A')} | æ¥æº: {code.get('source', 'N/A')}")
            result.append("")
        
        # åˆ†é¡µä¿¡æ¯
        total_pages = (total + per_page - 1) // per_page
        if total_pages > 1:
            result.append(f"ğŸ“„ ç¬¬{page}/{total_pages}é¡µ")
            if page < total_pages:
                result.append("ğŸ’¡ è¾“å…¥ 'ä¸‹ä¸€é¡µ' æŸ¥çœ‹æ›´å¤š")
        
        return "\n".join(result)
    
    def filter_codes(self, args):
        """ç­›é€‰ç¼–ç """
        category = args.get("category", "")
        measurement_kind = args.get("measurement_kind", "")
        
        filtered_codes = self.reading_type_codes
        
        # æŒ‰ç±»åˆ«ç­›é€‰
        if category:
            filtered_codes = [code for code in filtered_codes if category.lower() in code.get('category', '').lower()]
        
        # æŒ‰æµ‹é‡ç±»å‹ç­›é€‰
        if measurement_kind:
            filtered_codes = [code for code in filtered_codes if measurement_kind.lower() in code.get('name', '').lower()]
        
        if not filtered_codes:
            return f"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç¼–ç  (ç±»åˆ«: {category}, æµ‹é‡ç±»å‹: {measurement_kind})"
        
        result = [f"ğŸ” ç­›é€‰ç»“æœ (å…±{len(filtered_codes)}æ¡):"]
        
        for code in filtered_codes[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
            result.append(f"â€¢ {code.get('name', 'N/A')}")
            result.append(f"  ID: {code.get('reading_type_id', 'N/A')}")
            result.append(f"  ç±»åˆ«: {code.get('category', 'N/A')}")
        
        if len(filtered_codes) > 10:
            result.append(f"\n... è¿˜æœ‰ {len(filtered_codes) - 10} ä¸ªç»“æœ")
        
        return "\n".join(result)
    
    def add_to_library(self, args):
        """æ·»åŠ ç¼–ç åˆ°åº“ä¸­"""
        name = args.get("name", "")
        reading_type_id = args.get("reading_type_id", "")
        description = args.get("description", "")
        category = args.get("category", "ç”¨æˆ·ç”Ÿæˆ")
        
        if not name or not reading_type_id:
            return "âŒ è¯·æä¾›ç¼–ç åç§°å’ŒReadingTypeID"
        
        # éªŒè¯ç¼–ç æ ¼å¼
        if not self.validate_reading_type_id(reading_type_id):
            return "âŒ ReadingTypeIDæ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä¸º16ä¸ªæ•°å­—ç”¨'-'åˆ†éš”"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        for code in self.reading_type_codes:
            if (code.get('name', '').lower() == name.lower() or 
                code.get('reading_type_id', '') == reading_type_id):
                return f"âŒ ç¼–ç å·²å­˜åœ¨: {code.get('name', 'N/A')} ({code.get('reading_type_id', 'N/A')})"
        
        # æ·»åŠ æ–°ç¼–ç 
        new_code = {
            'id': len(self.reading_type_codes) + 1,
            'name': name,
            'description': description,
            'reading_type_id': reading_type_id,
            'created_at': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'source': 'ç”¨æˆ·ç”Ÿæˆ',
            'category': category
        }
        
        # è§£æå­—æ®µå€¼
        fields = reading_type_id.split('-')
        for i, field_value in enumerate(fields):
            new_code[f'field_{i+1}'] = field_value
        
        self.reading_type_codes.append(new_code)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self.save_reading_type_codes()
        
        # è®°å½•æ“ä½œå†å²
        self.log_operation(f"æ·»åŠ ç¼–ç : {name}", "add", f"æˆåŠŸæ·»åŠ ç¼–ç  {reading_type_id}")
        
        return f"âœ… æˆåŠŸæ·»åŠ ç¼–ç åˆ°åº“ä¸­:\nğŸ“Š åç§°: {name}\nğŸ”¢ ID: {reading_type_id}\nğŸ“ è¯´æ˜: {description}"
    
    def validate_reading_type_id(self, reading_type_id):
        """éªŒè¯ReadingTypeIDæ ¼å¼"""
        parts = reading_type_id.split('-')
        if len(parts) != 16:
            return False
        
        for part in parts:
            try:
                float(part)  # å…è®¸å°æ•°å’Œè´Ÿæ•°
            except ValueError:
                return False
        
        return True
    
    def save_reading_type_codes(self):
        """ä¿å­˜ç¼–ç åº“åˆ°æ–‡ä»¶"""
        try:
            df = pd.DataFrame(self.reading_type_codes)
            df.to_csv(self.codes_file, index=False)
        except Exception as e:
            print(f"ä¿å­˜ç¼–ç åº“å¤±è´¥: {e}")
    
    def export_data(self, args):
        """å¯¼å‡ºæ•°æ®"""
        format_type = args.get("format", "csv").lower()
        filter_category = args.get("category", "")
        
        # ç­›é€‰æ•°æ®
        export_data = self.reading_type_codes
        if filter_category:
            export_data = [code for code in export_data if code.get('category', '').lower() == filter_category.lower()]
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"reading_type_export_{timestamp}.{format_type}"
        
        try:
            if format_type == "csv":
                df = pd.DataFrame(export_data)
                df.to_csv(filename, index=False)
            elif format_type == "json":
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(export_data, f, ensure_ascii=False, indent=2)
            else:
                return "âŒ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ: csv, json"
            
            return f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°æ–‡ä»¶: {filename}\nğŸ“Š å…±å¯¼å‡º {len(export_data)} æ¡è®°å½•"
        
        except Exception as e:
            return f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}"
    
    def similarity(self, a, b):
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦"""
        return SequenceMatcher(None, a.lower(), b.lower()).ratio()
    
    def log_operation(self, input_text, operation_type, result, user_action="pending"):
        """è®°å½•æ“ä½œå†å²"""
        try:
            history_entry = {
                'id': '',  # ç”±CSVæ–‡ä»¶è¡Œæ•°å†³å®š
                'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'input_text': input_text,
                'operation_type': operation_type,
                'result': result[:200] + "..." if len(result) > 200 else result,  # é™åˆ¶é•¿åº¦
                'user_action': user_action
            }
            
            # è¿½åŠ åˆ°å†å²æ–‡ä»¶
            file_exists = os.path.isfile(self.history_file)
            with open(self.history_file, 'a', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=history_entry.keys())
                if not file_exists:
                    writer.writeheader()
                writer.writerow(history_entry)
        
        except Exception as e:
            print(f"è®°å½•å†å²å¤±è´¥: {e}")
    
    def handle_function_call(self, function_call):
        """å¤„ç†å‡½æ•°è°ƒç”¨"""
        function_name = function_call.get("name")
        function_args = {}
        
        if function_call.get("arguments"):
            try:
                function_args = json.loads(function_call.get("arguments", "{}"))
            except:
                pass
        
        if function_name in self.available_tools:
            function_response = self.available_tools[function_name](function_args)
            
            # æ·»åŠ å‡½æ•°ç»“æœåˆ°å¯¹è¯å†å²
            self.add_message(
                "function",
                {
                    "name": function_name,
                    "content": function_response
                }
            )
            
            return function_response
        else:
            return f"é”™è¯¯: æœªçŸ¥çš„å‡½æ•° '{function_name}'"
    
    def get_response(self, user_input, stream=True):
        """è·å–AIçš„å›å¤"""
        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²
        self.add_message("user", user_input)
        
        try:
            # åˆ›å»ºå¯ç”¨å·¥å…·çš„æè¿°
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "search_reading_type",
                        "description": "åœ¨ReadingTypeç¼–ç åº“ä¸­æœç´¢åŒ¹é…çš„ç¼–ç ",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "name": {
                                    "type": "string",
                                    "description": "è¦æœç´¢çš„é‡æµ‹åç§°æˆ–å…³é”®è¯"
                                }
                            },
                            "required": ["name"]
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "generate_reading_type",
                        "description": "æ ¹æ®æè¿°æˆ–å­—æ®µå€¼ç”ŸæˆReadingTypeID",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "description": {
                                    "type": "string",
                                    "description": "é‡æµ‹çš„è¯¦ç»†æè¿°"
                                },
                                "field_values": {
                                    "type": "object",
                                    "description": "å…·ä½“çš„å­—æ®µå€¼å­—å…¸"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "query_dictionary",
                        "description": "æŸ¥è¯¢ReadingTypeå­—æ®µå­—å…¸ä¿¡æ¯",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "field_name": {
                                    "type": "string",
                                    "description": "è¦æŸ¥è¯¢çš„å­—æ®µåç§°"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "view_codes_library",
                        "description": "æŸ¥çœ‹ç¼–ç åº“å†…å®¹",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "page": {
                                    "type": "integer",
                                    "description": "é¡µç ï¼Œé»˜è®¤ä¸º1"
                                },
                                "per_page": {
                                    "type": "integer", 
                                    "description": "æ¯é¡µæ˜¾ç¤ºæ•°é‡ï¼Œé»˜è®¤ä¸º20"
                                },
                                "category": {
                                    "type": "string",
                                    "description": "ç­›é€‰çš„ç±»åˆ«"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "filter_codes",
                        "description": "ç­›é€‰ç¼–ç åº“",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "category": {
                                    "type": "string",
                                    "description": "æŒ‰ç±»åˆ«ç­›é€‰"
                                },
                                "measurement_kind": {
                                    "type": "string",
                                    "description": "æŒ‰æµ‹é‡ç±»å‹ç­›é€‰"
                                }
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "add_to_library",
                        "description": "æ·»åŠ æ–°ç¼–ç åˆ°åº“ä¸­",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "name": {
                                    "type": "string",
                                    "description": "ç¼–ç åç§°"
                                },
                                "reading_type_id": {
                                    "type": "string",
                                    "description": "ReadingTypeIDç¼–ç "
                                },
                                "description": {
                                    "type": "string",
                                    "description": "ç¼–ç è¯´æ˜"
                                },
                                "category": {
                                    "type": "string",
                                    "description": "ç¼–ç ç±»åˆ«"
                                }
                            },
                            "required": ["name", "reading_type_id"]
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "export_data",
                        "description": "å¯¼å‡ºç¼–ç åº“æ•°æ®",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "format": {
                                    "type": "string",
                                    "description": "å¯¼å‡ºæ ¼å¼ (csv/json)"
                                },
                                "category": {
                                    "type": "string",
                                    "description": "ç­›é€‰å¯¼å‡ºçš„ç±»åˆ«"
                                }
                            }
                        }
                    }
                }
            ]
            
            # è°ƒç”¨DeepSeek APIï¼Œéæµå¼æ–¹å¼ï¼Œå› ä¸ºéœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=self.conversation_history,
                tools=tools,
                tool_choice="auto",
                stream=False  # å·¥å…·è°ƒç”¨æ—¶ä½¿ç”¨éæµå¼
            )
            
            response_message = response.choices[0].message
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if hasattr(response_message, 'tool_calls') and response_message.tool_calls:
                print("\nğŸ¤– ReadingTypeåŠ©æ‰‹æ­£åœ¨å¤„ç†...")
                
                # æ·»åŠ åŠ©æ‰‹çš„å“åº”åˆ°å¯¹è¯å†å²
                self.add_message("assistant", response_message)
                
                # å¤„ç†æ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in response_message.tool_calls:
                    function_info = {
                        "name": tool_call.function.name,
                        "arguments": tool_call.function.arguments
                    }
                    tool_result = self.handle_function_call(function_info)
                    print(f"ğŸ”§ å·¥å…·ä½¿ç”¨: {tool_call.function.name}")
                
                # å†æ¬¡è°ƒç”¨APIè·å–æœ€ç»ˆå›å¤ï¼Œè¿™æ¬¡ä½¿ç”¨æµå¼è¾“å‡º
                if stream:
                    print("\nğŸ¤– ReadingTypeåŠ©æ‰‹: ", end="", flush=True)
                    second_response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=self.conversation_history,
                        stream=True
                    )
                    
                    full_response = ""
                    for chunk in second_response:
                        if chunk.choices and len(chunk.choices) > 0:
                            content = chunk.choices[0].delta.content
                            if content:
                                print(content, end="", flush=True)
                                full_response += content
                    
                    print()  # æ¢è¡Œ
                    ai_response = full_response
                else:
                    second_response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=self.conversation_history,
                        stream=False
                    )
                    ai_response = second_response.choices[0].message.content
                    print(f"\nğŸ¤– ReadingTypeåŠ©æ‰‹: {ai_response}")
                
                self.add_message("assistant", ai_response)
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å›å¤
                if stream:
                    # ç”±äºå·²ç»è·å–äº†éæµå¼å“åº”ï¼Œç›´æ¥æ‰“å°
                    ai_response = response_message.content
                    print(f"\nğŸ¤– ReadingTypeåŠ©æ‰‹: {ai_response}")
                else:
                    ai_response = response_message.content
                    print(f"\nğŸ¤– ReadingTypeåŠ©æ‰‹: {ai_response}")
                
                self.add_message("assistant", ai_response)
            
            return ai_response
        
        except Exception as e:
            error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"\nğŸ¤– ReadingTypeåŠ©æ‰‹: {error_msg}")
            return error_msg

    def clear_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        self.conversation_history = []


def main():
    print("ğŸš€ ReadingTypeIDæ™ºèƒ½ç¼–ç åŠ©æ‰‹")
    print("=" * 50)
    print("ğŸ’¡ æˆ‘å¯ä»¥å¸®æ‚¨:")
    print("   â€¢ æœç´¢ç°æœ‰çš„ReadingTypeç¼–ç ")
    print("   â€¢ ç”Ÿæˆæ–°çš„ReadingTypeID")
    print("   â€¢ æŸ¥è¯¢å­—æ®µå­—å…¸ä¿¡æ¯")
    print("   â€¢ ç®¡ç†ç¼–ç åº“")
    print("   â€¢ å¯¼å‡ºæ•°æ®")
    print("\nğŸ“ æ”¯æŒè‡ªç„¶è¯­è¨€å¯¹è¯ï¼Œè¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")
    print("ğŸ” ç¤ºä¾‹: 'æœ‰åŠŸç”µèƒ½' / 'ç”Ÿæˆå‚¨èƒ½å……ç”µåŠŸç‡ç¼–ç ' / 'æŸ¥çœ‹ç¼–ç åº“'")
    print("=" * 50)
    
    # åˆ›å»ºAIåŠ©æ‰‹å®ä¾‹
    agent = ReadingTypeAgent()
    
    # è®¾ç½®ç³»ç»Ÿæ¶ˆæ¯
    agent.add_message("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ReadingTypeIDç¼–ç åŠ©æ‰‹ï¼ŒåŸºäºIEC61968-9-2024æ ‡å‡†ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

1. ç†è§£ç”¨æˆ·çš„é‡æµ‹éœ€æ±‚ï¼Œæœç´¢ç°æœ‰ç¼–ç æˆ–ç”Ÿæˆæ–°ç¼–ç 
2. æä¾›å‡†ç¡®çš„ReadingTypeç¼–ç ä¿¡æ¯å’Œè§£é‡Š
3. ç®¡ç†å’Œç»´æŠ¤ç¼–ç åº“
4. å¯¼å‡ºå’Œåˆ†æç¼–ç æ•°æ®

æ ¸å¿ƒåŸåˆ™ï¼š
- å‡†ç¡®ç†è§£ç”¨æˆ·æ„å›¾ï¼Œæä¾›ç²¾ç¡®çš„ç¼–ç ä¿¡æ¯
- å¯¹äºæ¨¡ç³Šçš„éœ€æ±‚ï¼Œä¸»åŠ¨è¯¢é—®ç»†èŠ‚
- è§£é‡Šç¼–ç çš„å«ä¹‰å’Œæ ‡å‡†ä¾æ®
- ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„å¯¹è¯é£æ ¼
- ä½¿ç”¨emojiå¢å¼ºå¯è¯»æ€§

å½“ç”¨æˆ·æåŠå…·ä½“çš„é‡æµ‹åç§°æ—¶ï¼Œä¼˜å…ˆæœç´¢ç°æœ‰ç¼–ç ã€‚
å½“ç”¨æˆ·è¦æ±‚ç”Ÿæˆæ–°ç¼–ç æ—¶ï¼Œåˆ†ææè¿°å¹¶æ˜ å°„åˆ°æ­£ç¡®çš„å­—æ®µå€¼ã€‚
å½“ç”¨æˆ·è¯¢é—®å­—å…¸ä¿¡æ¯æ—¶ï¼Œæä¾›æ¸…æ™°çš„å­—æ®µè¯´æ˜ã€‚""")
    
    # å¯¹è¯å¾ªç¯
    while True:
        user_input = input("\nğŸ’¬ æ‚¨: ")
        
        if user_input.lower() in ["é€€å‡º", "exit", "quit", "å†è§"]:
            print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨ReadingTypeIDç¼–ç åŠ©æ‰‹!")
            break
        
        if user_input.strip() == "":
            continue
        
        # è·å–AIå›å¤ï¼ˆå†…éƒ¨å·²å¤„ç†è¾“å‡ºï¼‰
        agent.get_response(user_input)


if __name__ == "__main__":
    main() 