import re
import json
from typing import Dict, List, Optional, Tuple, Set
from difflib import SequenceMatcher
from collections import defaultdict

class EnhancedSemanticParser:
    """å¢å¼ºç‰ˆè¯­ä¹‰è§£æå™¨ï¼Œæä¾›æ›´å‡†ç¡®çš„ReadingTypeå­—æ®µå€¼è§£æ"""
    
    def __init__(self, dictionary_manager=None):
        self.dictionary_manager = dictionary_manager
        
        # ReadingTypeå­—æ®µå®šä¹‰
        self.field_names = [
            "macroPeriod", "aggregate", "measurePeriod", "accumulationBehaviour",
            "flowDirection", "commodity", "measurementKind", "harmonic",
            "argumentNumerator", "TOU", "cpp", "tier", "phase", "multiplier", "uom", "currency"
        ]
        
        # åˆå§‹åŒ–å¢å¼ºçš„å…³é”®è¯æ˜ å°„
        self.enhanced_mappings = self._init_enhanced_mappings()
        
        # åŒä¹‰è¯è¯å…¸
        self.synonyms = self._init_synonyms()
        
        # ä¸Šä¸‹æ–‡è§„åˆ™
        self.context_rules = self._init_context_rules()
        
        # å­—æ®µä¾èµ–å…³ç³»
        self.field_dependencies = self._init_field_dependencies()
    
    def _init_enhanced_mappings(self) -> Dict:
        """åˆå§‹åŒ–å¢å¼ºçš„å…³é”®è¯æ˜ å°„è§„åˆ™"""
        return {
            'commodity': {
                'patterns': [
                    # ç”µåŠ›ç›¸å…³
                    {'value': 1, 'keywords': ['ç”µ', 'ç”µåŠ›', 'ç”µèƒ½', 'ç”µå‹', 'ç”µæµ', 'åŠŸç‡'], 'weight': 10},
                    {'value': 1, 'keywords': ['electricity', 'electric', 'power', 'voltage', 'current'], 'weight': 8},
                    
                    # å‚¨èƒ½ç›¸å…³
                    {'value': 41, 'keywords': ['å‚¨èƒ½', 'ç”µæ± ', 'PCS', 'å……ç”µ', 'æ”¾ç”µ'], 'weight': 15},
                    {'value': 41, 'keywords': ['battery', 'energy storage', 'pcs', 'charge', 'discharge'], 'weight': 12},
                    
                    # æ°´ç›¸å…³
                    {'value': 4, 'keywords': ['æ°´'], 'weight': 10},
                    {'value': 4, 'keywords': ['water'], 'weight': 8},
                    
                    # æ°”ä½“ç›¸å…³
                    {'value': 7, 'keywords': ['æ°”', 'å¤©ç„¶æ°”', 'ç‡ƒæ°”'], 'weight': 10},
                    {'value': 7, 'keywords': ['gas', 'natural gas'], 'weight': 8},
                    
                    # çƒ­èƒ½ç›¸å…³
                    {'value': 6, 'keywords': ['çƒ­', 'è’¸æ±½', 'çƒ­èƒ½'], 'weight': 10},
                    {'value': 6, 'keywords': ['heat', 'steam', 'thermal'], 'weight': 8},
                    
                    # æ°”è±¡ç›¸å…³
                    {'value': 40, 'keywords': ['æ°”è±¡', 'ç¯å¢ƒ', 'å¤©æ°”', 'æ¸©åº¦', 'æ¹¿åº¦', 'é£é€Ÿ'], 'weight': 12},
                    {'value': 40, 'keywords': ['weather', 'environment', 'temperature', 'humidity'], 'weight': 10}
                ],
                'default': 1
            },
            
            'measurementKind': {
                'patterns': [
                    # ç”µå‹ç›¸å…³
                    {'value': 54, 'keywords': ['ç”µå‹', 'ç”µä½', 'çº¿ç”µå‹', 'ç›¸ç”µå‹'], 'weight': 15},
                    {'value': 158, 'keywords': ['å•ç›¸ç”µå‹', 'ç›¸ç”µå‹'], 'weight': 16},
                    {'value': 54, 'keywords': ['voltage', 'potential'], 'weight': 12},
                    
                    # ç”µæµç›¸å…³
                    {'value': 4, 'keywords': ['ç”µæµ'], 'weight': 15},
                    {'value': 4, 'keywords': ['current'], 'weight': 12},
                    
                    # åŠŸç‡ç›¸å…³
                    {'value': 37, 'keywords': ['æœ‰åŠŸåŠŸç‡', 'æœ‰åŠŸ'], 'weight': 16},
                    {'value': 53, 'keywords': ['æ— åŠŸåŠŸç‡', 'æ— åŠŸ'], 'weight': 16},
                    {'value': 15, 'keywords': ['è§†åœ¨åŠŸç‡', 'è§†åœ¨'], 'weight': 16},
                    {'value': 37, 'keywords': ['active power'], 'weight': 13},
                    {'value': 53, 'keywords': ['reactive power'], 'weight': 13},
                    {'value': 15, 'keywords': ['apparent power'], 'weight': 13},
                    
                    # èƒ½é‡ç›¸å…³
                    {'value': 12, 'keywords': ['èƒ½é‡', 'ç”µèƒ½', 'ç”µåº¦'], 'weight': 15},
                    {'value': 12, 'keywords': ['energy'], 'weight': 12},
                    
                    # é¢‘ç‡ç›¸å…³
                    {'value': 46, 'keywords': ['é¢‘ç‡'], 'weight': 15},
                    {'value': 46, 'keywords': ['frequency'], 'weight': 12},
                    
                    # æ¸©åº¦ç›¸å…³
                    {'value': 139, 'keywords': ['æ¸©åº¦'], 'weight': 15},
                    {'value': 139, 'keywords': ['temperature'], 'weight': 12},
                    
                    # çŠ¶æ€ç›¸å…³
                    {'value': 118, 'keywords': ['çŠ¶æ€', 'å‘Šè­¦', 'æŠ¥è­¦', 'å¼€å…³', 'é¥ä¿¡'], 'weight': 14},
                    {'value': 183, 'keywords': ['å……ç”µçŠ¶æ€', 'æ”¾ç”µçŠ¶æ€'], 'weight': 16},
                    {'value': 904, 'keywords': ['è¿œæ–¹', 'å°±åœ°', 'æœ¬åœ°'], 'weight': 14},
                    {'value': 11, 'keywords': ['å¹¶ç½‘', 'ç¦»ç½‘'], 'weight': 14},
                    
                    # å®¹é‡ç›¸å…³
                    {'value': 119, 'keywords': ['å®¹é‡', 'soc', 'è·ç”µçŠ¶æ€'], 'weight': 15},
                    
                    # åŠŸç‡å› æ•°
                    {'value': 38, 'keywords': ['åŠŸç‡å› æ•°', 'åŠŸå› '], 'weight': 16},
                    
                    # æ§åˆ¶ç³»æ•°
                    {'value': 121, 'keywords': ['æ§åˆ¶ç³»æ•°'], 'weight': 16}
                ],
                'default': 0
            },
            
            'flowDirection': {
                'patterns': [
                    {'value': 1, 'keywords': ['æ­£å‘', 'å……ç”µ', 'è¿›', 'è¾“å…¥', 'é€ç”µ'], 'weight': 15},
                    {'value': 19, 'keywords': ['åå‘', 'æ”¾ç”µ', 'å‡º', 'è¾“å‡º', 'å›ç”µ'], 'weight': 15},
                    {'value': 4, 'keywords': ['å‡€', 'åŒå‘', 'å‡€å€¼'], 'weight': 14},
                    {'value': 20, 'keywords': ['å……æ”¾ç”µ', 'pcs'], 'weight': 16}
                ],
                'default': 0
            },
            
            'accumulationBehaviour': {
                'patterns': [
                    {'value': 3, 'keywords': ['ç´¯ç§¯', 'ç´¯è®¡', 'æ€»', 'åˆè®¡'], 'weight': 15},
                    {'value': 6, 'keywords': ['ç¬æ—¶', 'å½“å‰', 'å®æ—¶', 'å³æ—¶'], 'weight': 15},
                    {'value': 4, 'keywords': ['é—´éš”', 'åŒºé—´', 'å·®å€¼'], 'weight': 14},
                    {'value': 1, 'keywords': ['å®¹é‡', 'æ€»é‡'], 'weight': 13},
                    {'value': 10, 'keywords': ['è®¡åˆ’'], 'weight': 12}
                ],
                'default': 6
            },
            
            'measurePeriod': {
                'patterns': [
                    {'value': 2, 'keywords': ['15åˆ†é’Ÿ', '15min'], 'weight': 18},
                    {'value': 6, 'keywords': ['5åˆ†é’Ÿ', '5min'], 'weight': 18},
                    {'value': 3, 'keywords': ['1åˆ†é’Ÿ', '1min'], 'weight': 18},
                    {'value': 7, 'keywords': ['60åˆ†é’Ÿ', '1å°æ—¶', 'å°æ—¶'], 'weight': 16},
                    {'value': 4, 'keywords': ['24å°æ—¶', 'æ—¥', 'å¤©'], 'weight': 15},
                    {'value': 0, 'keywords': ['ç¬æ—¶', 'å®æ—¶', 'æ— å‘¨æœŸ'], 'weight': 14}
                ],
                'default': 0
            },
            
            'phase': {
                'patterns': [
                    {'value': 128, 'keywords': ['aç›¸', 'ç”²ç›¸'], 'weight': 18},
                    {'value': 64, 'keywords': ['bç›¸', 'ä¹™ç›¸'], 'weight': 18},
                    {'value': 32, 'keywords': ['cç›¸', 'ä¸™ç›¸'], 'weight': 18},
                    {'value': 224, 'keywords': ['ä¸‰ç›¸', 'æ€»', 'åˆè®¡'], 'weight': 16},
                    {'value': 225, 'keywords': ['å¹³å‡'], 'weight': 15}
                ],
                'default': 0
            },
            
            'multiplier': {
                'patterns': [
                    {'value': 3, 'keywords': ['k', 'kw', 'kwh', 'åƒ'], 'weight': 15},
                    {'value': 6, 'keywords': ['m', 'mw', 'mwh', 'å…†'], 'weight': 15},
                    {'value': 0, 'keywords': ['åŸºæœ¬', 'åŸºç¡€'], 'weight': 10}
                ],
                'default': 0
            },
            
            'uom': {
                'patterns': [
                    {'value': 72, 'keywords': ['wh', 'ç“¦æ—¶', 'ç”µèƒ½'], 'weight': 16},
                    {'value': 38, 'keywords': ['w', 'ç“¦', 'åŠŸç‡'], 'weight': 16},
                    {'value': 29, 'keywords': ['v', 'ä¼', 'ç”µå‹'], 'weight': 16},
                    {'value': 5, 'keywords': ['a', 'å®‰', 'ç”µæµ'], 'weight': 16},
                    {'value': 23, 'keywords': ['hz', 'èµ«å…¹', 'é¢‘ç‡'], 'weight': 16},
                    {'value': 109, 'keywords': ['Â°c', 'æ‘„æ°åº¦', 'æ¸©åº¦'], 'weight': 15},
                    {'value': 0, 'keywords': ['æ— å•ä½', 'çŠ¶æ€', 'æ¯”ç‡'], 'weight': 12}
                ],
                'default': 0
            }
        }
    
    def _init_synonyms(self) -> Dict[str, Set[str]]:
        """åˆå§‹åŒ–åŒä¹‰è¯è¯å…¸"""
        return {
            'ç”µåŠ›': {'ç”µ', 'ç”µèƒ½', 'ç”µé‡', 'ç”µåº¦'},
            'åŠŸç‡': {'power', 'ç“¦', 'w'},
            'ç”µå‹': {'voltage', 'ä¼', 'v', 'ç”µä½'},
            'ç”µæµ': {'current', 'å®‰', 'a'},
            'é¢‘ç‡': {'frequency', 'hz', 'èµ«å…¹'},
            'æ¸©åº¦': {'temperature', 'æ¸©', 'æ‘„æ°', 'åæ°'},
            'ç¬æ—¶': {'å®æ—¶', 'å½“å‰', 'å³æ—¶', 'ç°æ—¶'},
            'ç´¯ç§¯': {'ç´¯è®¡', 'æ€»è®¡', 'åˆè®¡', 'æ€»'},
            'ä¸‰ç›¸': {'ä¸‰ç›¸åˆ¶', 'ä¸‰ç›¸ç³»ç»Ÿ'},
            'å‚¨èƒ½': {'ç”µæ± ', 'è“„ç”µæ± ', 'å‚¨ç”µ'},
            'å……ç”µ': {'å……', 'è¿›ç”µ', 'è¾“å…¥'},
            'æ”¾ç”µ': {'æ”¾', 'å‡ºç”µ', 'è¾“å‡º'}
        }
    
    def _init_context_rules(self) -> List[Dict]:
        """åˆå§‹åŒ–ä¸Šä¸‹æ–‡è§„åˆ™"""
        return [
            # å‚¨èƒ½ç›¸å…³ç»„åˆ
            {
                'conditions': ['å‚¨èƒ½', 'pcs'],
                'field_updates': {
                    'commodity': 41,
                    'flowDirection': 20
                }
            },
            
            # ç”µèƒ½è¡¨ç›¸å…³
            {
                'conditions': ['ç”µèƒ½', 'ç´¯ç§¯'],
                'field_updates': {
                    'commodity': 1,
                    'measurementKind': 12,
                    'accumulationBehaviour': 3,
                    'uom': 72
                }
            },
            
            # åŠŸç‡è¡¨ç›¸å…³
            {
                'conditions': ['åŠŸç‡', 'ç¬æ—¶'],
                'field_updates': {
                    'commodity': 1,
                    'accumulationBehaviour': 6,
                    'uom': 38
                }
            },
            
            # æ°”è±¡ç«™ç›¸å…³
            {
                'conditions': ['æ¸©åº¦', 'ç¯å¢ƒ'],
                'field_updates': {
                    'commodity': 40,
                    'measurementKind': 139,
                    'uom': 109
                }
            }
        ]
    
    def _init_field_dependencies(self) -> Dict[str, List[Tuple[str, Dict]]]:
        """åˆå§‹åŒ–å­—æ®µä¾èµ–å…³ç³»"""
        return {
            'measurementKind': [
                # ç”µèƒ½ -> Whå•ä½
                (12, {'uom': 72}),
                # åŠŸç‡ -> Wå•ä½
                (37, {'uom': 38}),
                (53, {'uom': 38}),
                (15, {'uom': 38}),
                # ç”µå‹ -> Vå•ä½
                (54, {'uom': 29}),
                # ç”µæµ -> Aå•ä½
                (4, {'uom': 5}),
                # é¢‘ç‡ -> Hzå•ä½
                (46, {'uom': 23}),
                # æ¸©åº¦ -> Â°Cå•ä½
                (139, {'uom': 109})
            ],
            
            'commodity': [
                # å‚¨èƒ½ -> å……æ”¾ç”µæµå‘
                (41, {'flowDirection': 20})
            ]
        }
    
    def analyze_description_enhanced(self, description: str) -> Tuple[Dict[str, int], float]:
        """å¢å¼ºç‰ˆæè¿°åˆ†æï¼Œè¿”å›ç»“æœå’Œç½®ä¿¡åº¦
        
        Args:
            description: ç”¨æˆ·è¾“å…¥çš„æè¿°
            
        Returns:
            (å­—æ®µå€¼å­—å…¸, ç½®ä¿¡åº¦åˆ†æ•° 0-1)
        """
        # é¢„å¤„ç†æ–‡æœ¬
        processed_text = self._preprocess_text(description)
        
        # åˆå§‹åŒ–åˆ†æç»“æœ
        analysis = {f"field_{i+1}": 0 for i in range(16)}
        confidence_scores = {}
        
        # 1. åŸºäºæ¨¡å¼åŒ¹é…çš„åˆ†æ
        pattern_results = self._analyze_with_patterns(processed_text)
        
        # 2. åº”ç”¨ä¸Šä¸‹æ–‡è§„åˆ™
        context_results = self._apply_context_rules(processed_text, pattern_results)
        
        # 3. åº”ç”¨å­—æ®µä¾èµ–å…³ç³»
        final_results = self._apply_field_dependencies(context_results)
        
        # 4. è®¡ç®—ç½®ä¿¡åº¦
        total_confidence = self._calculate_confidence(processed_text, final_results)
        
        # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
        for i, field_name in enumerate(self.field_names):
            field_key = f"field_{i+1}"
            if field_name in final_results:
                analysis[field_key] = final_results[field_name]['value']
                confidence_scores[field_key] = final_results[field_name]['confidence']
        
        return analysis, total_confidence
    
    def _preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬"""
        # è½¬æ¢ä¸ºå°å†™
        text = text.lower()
        
        # æ ‡å‡†åŒ–å•ä½
        unit_replacements = {
            'kw': 'k w', 'mw': 'm w', 'kwh': 'k wh', 'mwh': 'm wh',
            'kv': 'k v', 'mv': 'm v', 'ka': 'k a', 'ma': 'm a'
        }
        
        for old, new in unit_replacements.items():
            text = text.replace(old, new)
        
        # åŒä¹‰è¯æ›¿æ¢
        for main_word, synonyms in self.synonyms.items():
            for synonym in synonyms:
                text = text.replace(synonym, main_word)
        
        return text
    
    def _analyze_with_patterns(self, text: str) -> Dict[str, Dict]:
        """åŸºäºæ¨¡å¼åŒ¹é…è¿›è¡Œåˆ†æ"""
        results = {}
        
        for field_name, mapping in self.enhanced_mappings.items():
            best_match = {'value': mapping['default'], 'confidence': 0.1, 'matched_keywords': []}
            
            for pattern in mapping['patterns']:
                matched_keywords = []
                total_weight = 0
                
                for keyword in pattern['keywords']:
                    if keyword in text:
                        matched_keywords.append(keyword)
                        # è®¡ç®—æƒé‡ï¼Œè€ƒè™‘å…³é”®è¯é•¿åº¦å’Œå®Œæ•´åŒ¹é…
                        weight = pattern['weight'] * len(keyword)
                        if f" {keyword} " in text:  # å®Œæ•´è¯åŒ¹é…é¢å¤–åŠ æƒ
                            weight *= 1.5
                        total_weight += weight
                
                if matched_keywords:
                    confidence = min(0.95, total_weight / 100)  # å½’ä¸€åŒ–ç½®ä¿¡åº¦
                    if confidence > best_match['confidence']:
                        best_match = {
                            'value': pattern['value'],
                            'confidence': confidence,
                            'matched_keywords': matched_keywords
                        }
            
            results[field_name] = best_match
        
        return results
    
    def _apply_context_rules(self, text: str, pattern_results: Dict) -> Dict:
        """åº”ç”¨ä¸Šä¸‹æ–‡è§„åˆ™"""
        results = pattern_results.copy()
        
        for rule in self.context_rules:
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ¡ä»¶
            conditions_met = all(condition in text for condition in rule['conditions'])
            
            if conditions_met:
                # åº”ç”¨å­—æ®µæ›´æ–°
                for field_name, value in rule['field_updates'].items():
                    if field_name in results:
                        # æå‡ç½®ä¿¡åº¦
                        results[field_name]['value'] = value
                        results[field_name]['confidence'] = min(0.95, results[field_name]['confidence'] + 0.2)
                        results[field_name]['matched_keywords'].extend(rule['conditions'])
        
        return results
    
    def _apply_field_dependencies(self, results: Dict) -> Dict:
        """åº”ç”¨å­—æ®µä¾èµ–å…³ç³»"""
        updated_results = results.copy()
        
        for field_name, dependencies in self.field_dependencies.items():
            if field_name in results:
                current_value = results[field_name]['value']
                
                for dep_value, updates in dependencies:
                    if current_value == dep_value:
                        for update_field, update_value in updates.items():
                            if update_field in updated_results:
                                # å¦‚æœä¾èµ–å­—æ®µçš„ç½®ä¿¡åº¦è¾ƒä½ï¼Œåˆ™åº”ç”¨æ›´æ–°
                                if updated_results[update_field]['confidence'] < 0.7:
                                    updated_results[update_field]['value'] = update_value
                                    updated_results[update_field]['confidence'] = 0.8
        
        return updated_results
    
    def _calculate_confidence(self, text: str, results: Dict) -> float:
        """è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦"""
        confidences = [result['confidence'] for result in results.values() if result['confidence'] > 0.1]
        
        if not confidences:
            return 0.1
        
        # è®¡ç®—åŠ æƒå¹³å‡ç½®ä¿¡åº¦
        avg_confidence = sum(confidences) / len(confidences)
        
        # æ ¹æ®è¯†åˆ«çš„å­—æ®µæ•°é‡è°ƒæ•´
        recognized_fields = len([r for r in results.values() if r['confidence'] > 0.3])
        field_bonus = min(0.2, recognized_fields * 0.05)
        
        return min(0.95, avg_confidence + field_bonus)
    
    def enhanced_fuzzy_search(self, field_name: str, search_term: str, 
                            threshold: float = 0.6) -> List[Tuple[Dict, float]]:
        """å¢å¼ºçš„æ¨¡ç³Šæœç´¢åŠŸèƒ½
        
        Args:
            field_name: å­—æ®µå
            search_term: æœç´¢è¯
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            [(å­—å…¸é¡¹, ç›¸ä¼¼åº¦åˆ†æ•°)] åˆ—è¡¨
        """
        if not self.dictionary_manager or field_name not in self.dictionary_manager.field_dictionaries:
            return []
        
        results = []
        search_lower = search_term.lower()
        
        # é¢„å¤„ç†æœç´¢è¯
        processed_search = self._preprocess_text(search_term)
        
        for item in self.dictionary_manager.field_dictionaries[field_name]:
            scores = []
            
            # 1. æ˜¾ç¤ºåç§°åŒ¹é…
            display_name = str(item['display_name']).lower()
            scores.append(SequenceMatcher(None, search_lower, display_name).ratio())
            
            # 2. æè¿°åŒ¹é…
            description = str(item.get('description', '')).lower()
            if description:
                scores.append(SequenceMatcher(None, search_lower, description).ratio() * 0.8)
            
            # 3. å…³é”®è¯åŒ¹é…
            for keyword in processed_search.split():
                if keyword in display_name:
                    scores.append(0.9)
                if keyword in description:
                    scores.append(0.7)
            
            # 4. å€¼ç²¾ç¡®åŒ¹é…
            if str(item['value']) == search_term:
                scores.append(1.0)
            
            # å–æœ€é«˜åˆ†
            max_score = max(scores) if scores else 0
            
            if max_score >= threshold:
                results.append((item, max_score))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        return results
    
    def suggest_alternatives(self, analysis: Dict[str, int], confidence: float) -> List[str]:
        """åŸºäºç½®ä¿¡åº¦å»ºè®®æ›¿ä»£æ–¹æ¡ˆ"""
        suggestions = []
        
        if confidence < 0.5:
            suggestions.append("âš ï¸ è§£æç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®ï¼š")
            suggestions.append("1. æä¾›æ›´è¯¦ç»†çš„æè¿°")
            suggestions.append("2. ä½¿ç”¨æ ‡å‡†æœ¯è¯­ï¼ˆå¦‚ï¼šæœ‰åŠŸåŠŸç‡ã€ä¸‰ç›¸ç”µå‹ç­‰ï¼‰")
            suggestions.append("3. æ˜ç¡®è®¾å¤‡ç±»å‹å’Œæµ‹é‡å†…å®¹")
        
        elif confidence < 0.7:
            suggestions.append("ğŸ’¡ ä¸ºæé«˜å‡†ç¡®æ€§ï¼Œå»ºè®®è¡¥å……ï¼š")
            
            # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦ä¸ºé»˜è®¤å€¼
            key_fields = ['commodity', 'measurementKind', 'accumulationBehaviour']
            for i, field_name in enumerate(self.field_names):
                if field_name in key_fields:
                    field_key = f"field_{i+1}"
                    if analysis[field_key] == 0:
                        chinese_name = self._get_field_chinese_name(field_name)
                        suggestions.append(f"- æ˜ç¡®{chinese_name}ä¿¡æ¯")
        
        return suggestions
    
    def _get_field_chinese_name(self, field_name: str) -> str:
        """è·å–å­—æ®µä¸­æ–‡å"""
        chinese_names = {
            "commodity": "å•†å“ç±»å‹",
            "measurementKind": "æµ‹é‡ç±»å‹",
            "accumulationBehaviour": "ç´¯ç§¯è¡Œä¸º",
            "flowDirection": "æµå‘",
            "measurePeriod": "æµ‹é‡å‘¨æœŸ",
            "phase": "ç›¸ä½",
            "multiplier": "ä¹˜æ•°",
            "uom": "å•ä½"
        }
        return chinese_names.get(field_name, field_name)
    
    def export_analysis_report(self, description: str, analysis: Dict[str, int], 
                             confidence: float) -> str:
        """å¯¼å‡ºåˆ†ææŠ¥å‘Š"""
        report = []
        report.append("ğŸ“Š ç¼–ç åˆ†ææŠ¥å‘Š")
        report.append("=" * 50)
        report.append(f"ğŸ“ è¾“å…¥æè¿°: {description}")
        report.append(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.2%}")
        report.append("")
        
        # æ„å»ºReadingTypeID
        values = [str(analysis[f"field_{i+1}"]) for i in range(16)]
        reading_type_id = "-".join(values)
        report.append(f"ğŸ”¢ ç”Ÿæˆç¼–ç : {reading_type_id}")
        report.append("")
        
        # å­—æ®µè¯¦æƒ…
        report.append("ğŸ“‹ å­—æ®µè§£æè¯¦æƒ…:")
        for i, field_name in enumerate(self.field_names):
            field_key = f"field_{i+1}"
            value = analysis[field_key]
            if value != 0:  # åªæ˜¾ç¤ºéé›¶å­—æ®µ
                chinese_name = self._get_field_chinese_name(field_name)
                field_desc = self._get_field_value_description(field_name, value)
                report.append(f"  {chinese_name}: {value} ({field_desc})")
        
        # å»ºè®®
        suggestions = self.suggest_alternatives(analysis, confidence)
        if suggestions:
            report.append("")
            report.extend(suggestions)
        
        return "\n".join(report)
    
    def _get_field_value_description(self, field_name: str, value: int) -> str:
        """è·å–å­—æ®µå€¼æè¿°"""
        if self.dictionary_manager:
            return self.dictionary_manager.get_field_description(field_name, str(value))
        return f"å€¼: {value}"
    
    def build_reading_type_id(self, field_values: Dict[str, int]) -> str:
        """æ„å»ºReadingTypeIDå­—ç¬¦ä¸²"""
        values = []
        for i in range(16):
            field_key = f"field_{i+1}"
            values.append(str(field_values.get(field_key, 0)))
        return "-".join(values)
    
    def parse_reading_type_id(self, reading_type_id: str) -> Dict[str, int]:
        """è§£æReadingTypeIDå­—ç¬¦ä¸²
        
        Args:
            reading_type_id: ReadingTypeIDå­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "0-0-2-6-1-1-37-0-0-0-0-0-224-3-38-0"
            
        Returns:
            å­—æ®µå€¼å­—å…¸ {field_1: value1, field_2: value2, ...}
        """
        parts = reading_type_id.split('-')
        
        if len(parts) != 16:
            raise ValueError(f"ReadingTypeIDæ ¼å¼é”™è¯¯ï¼Œåº”åŒ…å«16ä¸ªå­—æ®µï¼Œå®é™…åŒ…å«{len(parts)}ä¸ª")
        
        field_values = {}
        for i, value in enumerate(parts):
            try:
                field_values[f"field_{i+1}"] = int(value)
            except ValueError:
                raise ValueError(f"å­—æ®µ{i+1}çš„å€¼'{value}'ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°")
        
        return field_values 